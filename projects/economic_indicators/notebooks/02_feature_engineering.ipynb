{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4e80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# COMPLETE ECONOMIC FORECASTING IMPLEMENTATION\n",
    "# Step-by-step: Data Processing â†’ Modeling â†’ Evaluation\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df65f764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistical models\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Prophet\n",
    "from prophet import Prophet\n",
    "\n",
    "# LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b613703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#economic_data = pd.read_csv(\"/Users/jessicabean/Library/CloudStorage/OneDrive-Personal/porftfolio.github.io/projects/economic_indicators/data/raw/economic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd2c2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 1: HANDLE MISSING VALUES\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f47d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, method='forward_fill'):\n",
    "    \"\"\"\n",
    "    Handle missing values in time series data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Time series data with datetime index\n",
    "    method : str\n",
    "        'forward_fill', 'interpolate', or 'hybrid'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Data with missing values handled\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 1: HANDLING MISSING VALUES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c09e8",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# STEP 2: TEST STATIONARITY & APPLY DIFFERENCING\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c3a21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(series, name='Series'):\n",
    "    \"\"\"\n",
    "    Perform Augmented Dickey-Fuller test for stationarity\n",
    "    \"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    \n",
    "    print(f\"\\nðŸ“Š ADF Test Results for {name}:\")\n",
    "    print(f\"   ADF Statistic: {result[0]:.6f}\")\n",
    "    print(f\"   p-value: {result[1]:.6f}\")\n",
    "    print(f\"   Critical Values:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"      {key}: {value:.3f}\")\n",
    "    \n",
    "    if result[1] < 0.05:\n",
    "        print(f\"   âœ… STATIONARY (p < 0.05)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"   âŒ NON-STATIONARY (p >= 0.05)\")\n",
    "        return False\n",
    "\n",
    "def make_stationary(df, columns=None):\n",
    "    \"\"\"\n",
    "    Apply differencing to non-stationary series\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Original time series data\n",
    "    columns : list\n",
    "        Columns to check and difference (None = all)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (df_stationary, difference_orders)\n",
    "        Stationary data and dict of difference orders applied\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2: TESTING STATIONARITY & DIFFERENCING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    \n",
    "    df_stationary = df.copy()\n",
    "    difference_orders = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        print(f\"\\nðŸ”¬ Testing: {col}\")\n",
    "        \n",
    "        series = df[col].dropna()\n",
    "        is_stationary = test_stationarity(series, col)\n",
    "        \n",
    "        if is_stationary:\n",
    "            difference_orders[col] = 0\n",
    "            continue\n",
    "        \n",
    "        # Try first difference\n",
    "        print(f\"\\n   Applying first difference...\")\n",
    "        diff1 = series.diff().dropna()\n",
    "        is_stationary_diff1 = test_stationarity(diff1, f\"{col} (1st diff)\")\n",
    "        \n",
    "        if is_stationary_diff1:\n",
    "            df_stationary[col] = df[col].diff()\n",
    "            difference_orders[col] = 1\n",
    "        else:\n",
    "            # Try second difference\n",
    "            print(f\"\\n   Applying second difference...\")\n",
    "            diff2 = diff1.diff().dropna()\n",
    "            is_stationary_diff2 = test_stationarity(diff2, f\"{col} (2nd diff)\")\n",
    "            \n",
    "            if is_stationary_diff2:\n",
    "                df_stationary[col] = df[col].diff().diff()\n",
    "                difference_orders[col] = 2\n",
    "            else:\n",
    "                print(f\"   âš ï¸ Still non-stationary after 2nd difference\")\n",
    "                df_stationary[col] = df[col].diff().diff()\n",
    "                difference_orders[col] = 2\n",
    "    \n",
    "    # Remove NaN created by differencing\n",
    "    df_stationary = df_stationary.dropna()\n",
    "    \n",
    "    print(\"\\nðŸ“Š Summary:\")\n",
    "    for col, order in difference_orders.items():\n",
    "        print(f\"   {col}: {'No differencing' if order == 0 else f'{order} difference(s)'}\")\n",
    "    \n",
    "    return df_stationary, difference_orders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ac7d0",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# STEP 3: FEATURE ENGINEERING\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f62dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_features(df, target_col, lags=[1, 3, 6, 12], rolling_windows=[3, 6, 12]):\n",
    "    \"\"\"\n",
    "    Create lag features and rolling statistics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Time series data\n",
    "    target_col : str\n",
    "        Target variable column name\n",
    "    lags : list\n",
    "        Lag periods to create\n",
    "    rolling_windows : list\n",
    "        Rolling window sizes for statistics\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Data with engineered features\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 3: FEATURE ENGINEERING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 1. LAG FEATURES\n",
    "    print(f\"\\nðŸ”§ Creating lag features for {target_col}...\")\n",
    "    for lag in lags:\n",
    "        df_features[f'{target_col}_lag_{lag}'] = df_features[target_col].shift(lag)\n",
    "        print(f\"   âœ“ Created lag_{lag}\")\n",
    "    \n",
    "    # 2. ROLLING STATISTICS\n",
    "    print(f\"\\nðŸ”§ Creating rolling statistics...\")\n",
    "    for window in rolling_windows:\n",
    "        # Rolling mean\n",
    "        df_features[f'{target_col}_rolling_mean_{window}'] = \\\n",
    "            df_features[target_col].rolling(window=window).mean()\n",
    "        \n",
    "        # Rolling std\n",
    "        df_features[f'{target_col}_rolling_std_{window}'] = \\\n",
    "            df_features[target_col].rolling(window=window).std()\n",
    "        \n",
    "        # Rolling min/max\n",
    "        df_features[f'{target_col}_rolling_min_{window}'] = \\\n",
    "            df_features[target_col].rolling(window=window).min()\n",
    "        \n",
    "        df_features[f'{target_col}_rolling_max_{window}'] = \\\n",
    "            df_features[target_col].rolling(window=window).max()\n",
    "        \n",
    "        print(f\"   âœ“ Created rolling features (window={window})\")\n",
    "    \n",
    "    # 3. RATE OF CHANGE\n",
    "    print(f\"\\nðŸ”§ Creating rate of change features...\")\n",
    "    df_features[f'{target_col}_pct_change_1'] = df_features[target_col].pct_change(1)\n",
    "    df_features[f'{target_col}_pct_change_12'] = df_features[target_col].pct_change(12)\n",
    "    print(f\"   âœ“ Created percent change features\")\n",
    "    \n",
    "    # 4. MOMENTUM INDICATORS\n",
    "    print(f\"\\nðŸ”§ Creating momentum indicators...\")\n",
    "    df_features[f'{target_col}_momentum'] = \\\n",
    "        df_features[target_col] - df_features[target_col].shift(12)\n",
    "    print(f\"   âœ“ Created momentum features\")\n",
    "    \n",
    "    # 5. DATE/TIME FEATURES\n",
    "    print(f\"\\nðŸ”§ Creating temporal features...\")\n",
    "    df_features['month'] = df_features.index.month\n",
    "    df_features['quarter'] = df_features.index.quarter\n",
    "    df_features['year'] = df_features.index.year\n",
    "    print(f\"   âœ“ Created temporal features\")\n",
    "    \n",
    "    # Remove NaN created by feature engineering\n",
    "    initial_rows = len(df_features)\n",
    "    df_features = df_features.dropna()\n",
    "    final_rows = len(df_features)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Feature Engineering Summary:\")\n",
    "    print(f\"   Original features: {len(df.columns)}\")\n",
    "    print(f\"   Total features: {len(df_features.columns)}\")\n",
    "    print(f\"   New features: {len(df_features.columns) - len(df.columns)}\")\n",
    "    print(f\"   Rows after cleaning: {final_rows} (removed {initial_rows - final_rows})\")\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c586d",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# STEP 4: BUILD FORECASTING MODELS\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffa6e9",
   "metadata": {},
   "source": [
    "# MODEL 1: ARIMA\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe31cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arima_model(train_data, test_data, order=(1,1,1)):\n",
    "    \"\"\"\n",
    "    Build and evaluate ARIMA model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data : pd.Series\n",
    "        Training data\n",
    "    test_data : pd.Series\n",
    "        Testing data\n",
    "    order : tuple\n",
    "        ARIMA order (p, d, q)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Model results and predictions\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL 1: ARIMA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Training ARIMA{order}...\")\n",
    "    \n",
    "    # Fit model\n",
    "    model = ARIMA(train_data, order=order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    print(f\"âœ… Model trained successfully!\")\n",
    "    print(f\"\\nModel Summary:\")\n",
    "    print(model_fit.summary())\n",
    "    \n",
    "    # Make predictions\n",
    "    print(f\"\\nðŸ“Š Generating predictions...\")\n",
    "    predictions = model_fit.forecast(steps=len(test_data))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(test_data, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test_data, predictions)\n",
    "    mape = np.mean(np.abs((test_data - predictions) / test_data)) * 100\n",
    "    r2 = r2_score(test_data, predictions)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Performance Metrics:\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    print(f\"   MAPE: {mape:.2f}%\")\n",
    "    print(f\"   RÂ² Score: {r2:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model_fit,\n",
    "        'predictions': predictions,\n",
    "        'metrics': {\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'R2': r2\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e2c6a",
   "metadata": {},
   "source": [
    "# MODEL 2: PROPHET\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bf4633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prophet_model(train_data, test_data, seasonality_mode='multiplicative'):\n",
    "    \"\"\"\n",
    "    Build and evaluate Prophet model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data : pd.Series\n",
    "        Training data with datetime index\n",
    "    test_data : pd.Series\n",
    "        Testing data with datetime index\n",
    "    seasonality_mode : str\n",
    "        'additive' or 'multiplicative'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Model results and predictions\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL 2: PROPHET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Training Prophet model (seasonality: {seasonality_mode})...\")\n",
    "    \n",
    "    # Prepare data for Prophet\n",
    "    train_df = pd.DataFrame({\n",
    "        'ds': train_data.index,\n",
    "        'y': train_data.values\n",
    "    })\n",
    "    \n",
    "    # Initialize and fit model\n",
    "    model = Prophet(\n",
    "        seasonality_mode=seasonality_mode,\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False,\n",
    "        changepoint_prior_scale=0.05\n",
    "    )\n",
    "    \n",
    "    model.fit(train_df)\n",
    "    print(f\"âœ… Model trained successfully!\")\n",
    "    \n",
    "    # Create future dataframe\n",
    "    future = pd.DataFrame({'ds': test_data.index})\n",
    "    \n",
    "    # Make predictions\n",
    "    print(f\"\\nðŸ“Š Generating predictions...\")\n",
    "    forecast = model.predict(future)\n",
    "    predictions = forecast['yhat'].values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(test_data, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test_data, predictions)\n",
    "    mape = np.mean(np.abs((test_data - predictions) / test_data)) * 100\n",
    "    r2 = r2_score(test_data, predictions)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Performance Metrics:\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    print(f\"   MAPE: {mape:.2f}%\")\n",
    "    print(f\"   RÂ² Score: {r2:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'forecast': forecast,\n",
    "        'predictions': predictions,\n",
    "        'metrics': {\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'R2': r2\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5bf99",
   "metadata": {},
   "source": [
    "# MODEL 3: LSTM\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8915aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(data, look_back=12):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM model\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:(i + look_back)])\n",
    "        y.append(data[i + look_back])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_lstm_model(train_data, test_data, look_back=12, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Build and evaluate LSTM model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data : pd.Series\n",
    "        Training data\n",
    "    test_data : pd.Series\n",
    "        Testing data\n",
    "    look_back : int\n",
    "        Number of previous time steps to use\n",
    "    epochs : int\n",
    "        Training epochs\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Model results and predictions\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL 3: LSTM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Preparing data for LSTM (look_back={look_back})...\")\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_scaled = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
    "    test_scaled = scaler.transform(test_data.values.reshape(-1, 1))\n",
    "    \n",
    "    # Prepare sequences\n",
    "    X_train, y_train = prepare_lstm_data(train_scaled.flatten(), look_back)\n",
    "    X_test, y_test = prepare_lstm_data(test_scaled.flatten(), look_back)\n",
    "    \n",
    "    # Reshape for LSTM [samples, time steps, features]\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    print(f\"   Train shape: {X_train.shape}\")\n",
    "    print(f\"   Test shape: {X_test.shape}\")\n",
    "    \n",
    "    # Build LSTM model\n",
    "    print(f\"\\nðŸ”§ Building LSTM architecture...\")\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(look_back, 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    print(f\"\\nModel Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nðŸ”§ Training LSTM model...\")\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Model trained successfully!\")\n",
    "    print(f\"   Final training loss: {history.history['loss'][-1]:.6f}\")\n",
    "    print(f\"   Final validation loss: {history.history['val_loss'][-1]:.6f}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    print(f\"\\nðŸ“Š Generating predictions...\")\n",
    "    predictions_scaled = model.predict(X_test, verbose=0)\n",
    "    predictions = scaler.inverse_transform(predictions_scaled)\n",
    "    \n",
    "    # Get actual test values (accounting for look_back)\n",
    "    test_actual = test_data.values[look_back:]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(test_actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test_actual, predictions)\n",
    "    mape = np.mean(np.abs((test_actual - predictions.flatten()) / test_actual)) * 100\n",
    "    r2 = r2_score(test_actual, predictions)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Performance Metrics:\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    print(f\"   MAPE: {mape:.2f}%\")\n",
    "    print(f\"   RÂ² Score: {r2:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'predictions': predictions.flatten(),\n",
    "        'history': history,\n",
    "        'look_back': look_back,\n",
    "        'test_actual': test_actual,\n",
    "        'metrics': {\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'R2': r2\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cac24",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# STEP 5: MODEL EVALUATION & COMPARISON\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e462e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models_dict, test_data, model_names=['ARIMA', 'Prophet', 'LSTM']):\n",
    "    \"\"\"\n",
    "    Compare performance of multiple models\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models_dict : dict\n",
    "        Dictionary of model results\n",
    "    test_data : pd.Series\n",
    "        Test data for comparison\n",
    "    model_names : list\n",
    "        Names of models to compare\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Comparison table\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 5: MODEL COMPARISON & EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for name in model_names:\n",
    "        if name in models_dict:\n",
    "            metrics = models_dict[name]['metrics']\n",
    "            comparison_data.append({\n",
    "                'Model': name,\n",
    "                'RMSE': metrics['RMSE'],\n",
    "                'MAE': metrics['MAE'],\n",
    "                'MAPE': f\"{metrics['MAPE']:.2f}%\",\n",
    "                'RÂ² Score': metrics['R2']\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"\\nðŸ“Š Model Performance Comparison:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_rmse = comparison_df.loc[comparison_df['RMSE'].idxmin(), 'Model']\n",
    "    best_model_r2 = comparison_df.loc[comparison_df['RÂ² Score'].idxmax(), 'Model']\n",
    "    \n",
    "    print(f\"\\nðŸ† Best Models:\")\n",
    "    print(f\"   Lowest RMSE: {best_model_rmse}\")\n",
    "    print(f\"   Highest RÂ²: {best_model_r2}\")\n",
    "    \n",
    "    return comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f22a1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# COMPLETE WORKFLOW FUNCTION\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acb42ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_forecasting_workflow(data, target_col, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Run complete forecasting workflow from data processing to evaluation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        Time series data with datetime index\n",
    "    target_col : str\n",
    "        Target variable to forecast\n",
    "    test_size : float\n",
    "        Proportion of data for testing\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : All results including processed data and model predictions\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸš€ COMPLETE ECONOMIC FORECASTING WORKFLOW\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTarget Variable: {target_col}\")\n",
    "    print(f\"Data Shape: {data.shape}\")\n",
    "    print(f\"Date Range: {data.index.min().date()} to {data.index.max().date()}\")\n",
    "    \n",
    "    # Step 1: Handle missing values\n",
    "    data_clean = handle_missing_values(data, method='hybrid')\n",
    "    \n",
    "    # Step 2: Test stationarity (keep original for modeling)\n",
    "    target_series = data_clean[target_col]\n",
    "    \n",
    "    # Step 3: Feature engineering (optional - for future use)\n",
    "    # data_features = create_features(data_clean, target_col)\n",
    "    \n",
    "    # Split data\n",
    "    split_idx = int(len(target_series) * (1 - test_size))\n",
    "    train_data = target_series[:split_idx]\n",
    "    test_data = target_series[split_idx:]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Data Split:\")\n",
    "    print(f\"   Training: {len(train_data)} samples ({train_data.index.min().date()} to {train_data.index.max().date()})\")\n",
    "    print(f\"   Testing: {len(test_data)} samples ({test_data.index.min().date()} to {test_data.index.max().date()})\")\n",
    "    \n",
    "    # Step 4: Build models\n",
    "    models_results = {}\n",
    "    \n",
    "    # ARIMA\n",
    "    try:\n",
    "        models_results['ARIMA'] = build_arima_model(train_data, test_data, order=(2,1,2))\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ARIMA failed: {e}\")\n",
    "    \n",
    "    # Prophet\n",
    "    try:\n",
    "        models_results['Prophet'] = build_prophet_model(train_data, test_data)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Prophet failed: {e}\")\n",
    "    \n",
    "    # LSTM\n",
    "    try:\n",
    "        models_results['LSTM'] = build_lstm_model(train_data, test_data, look_back=12, epochs=50)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ LSTM failed: {e}\")\n",
    "    \n",
    "    # Step 5: Compare and evaluate\n",
    "    comparison_df = compare_models(models_results, test_data)\n",
    "    \n",
    "    # Generate plots\n",
    "    plot_predictions(test_data, models_results)\n",
    "    plot_residuals(test_data, models_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… WORKFLOW COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        'data_clean': data_clean,\n",
    "        'train_data': train_data,\n",
    "        'test_data': test_data,\n",
    "        'models': models_results,\n",
    "        'comparison': comparison_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643db79",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbff6e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXAMPLE: Running Complete Workflow\n",
      "============================================================\n",
      "\n",
      "ðŸ’¡ To run this workflow with your data:\n",
      "\n",
      "# Load your data\n",
      "economic_data = pd.read_csv('economic_indicators.csv', index_col=0, parse_dates=True)\n",
      "\n",
      "# Run complete workflow\n",
      "results = complete_forecasting_workflow(\n",
      "    data=economic_data,\n",
      "    target_col='Unemployment Rate',  # or 'Consumer Price Index', etc.\n",
      "    test_size=0.2\n",
      ")\n",
      "\n",
      "# Access results\n",
      "comparison_table = results['comparison']\n",
      "best_model = results['models']['Prophet']  # or 'ARIMA', 'LSTM'\n",
      "\n",
      "âœ… All functions defined and ready to use!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE: Running Complete Workflow\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load your data (replace with your actual data)\n",
    "    # Assuming you have 'economic_data' from previous setup\n",
    "    \n",
    "    # For demo, let's create sample data\n",
    "    # In practice, use: economic_data = pd.read_csv('economic_indicators.csv', index_col=0, parse_dates=True)\n",
    "    \n",
    "    print(\"\\nðŸ’¡ To run this workflow with your data:\")\n",
    "    print(\"\\n# Load your data\")\n",
    "    print(\"economic_data = pd.read_csv('economic_indicators.csv', index_col=0, parse_dates=True)\")\n",
    "    print(\"\\n# Run complete workflow\")\n",
    "    print(\"results = complete_forecasting_workflow(\")\n",
    "    print(\"    data=economic_data,\")\n",
    "    print(\"    target_col='Unemployment Rate',  # or 'Consumer Price Index', etc.\")\n",
    "    print(\"    test_size=0.2\")\n",
    "    print(\")\")\n",
    "    print(\"\\n# Access results\")\n",
    "    print(\"comparison_table = results['comparison']\")\n",
    "    print(\"best_model = results['models']['Prophet']  # or 'ARIMA', 'LSTM'\")\n",
    "    \n",
    "    print(\"\\nâœ… All functions defined and ready to use!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34632a",
   "metadata": {},
   "source": [
    "###Load economic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93776d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "economic_data = pd.read_csv(\"/Users/jessicabean/Library/CloudStorage/OneDrive-Personal/porftfolio.github.io/projects/economic_indicators/data/raw/economic_data.csv\",\n",
    "                            index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55b043c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ COMPLETE ECONOMIC FORECASTING WORKFLOW\n",
      "============================================================\n",
      "\n",
      "Target Variable: unemployemnt\n",
      "Data Shape: (26169, 4)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mcomplete_forecasting_workflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43meconomic_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munemployemnt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'Consumer Price Index', etc.\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mcomplete_forecasting_workflow\u001b[39m\u001b[34m(data, target_col, test_size)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTarget Variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate Range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.index.max().date()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Step 1: Handle missing values\u001b[39;00m\n\u001b[32m     26\u001b[39m data_clean = handle_missing_values(data, method=\u001b[33m'\u001b[39m\u001b[33mhybrid\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.float64' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "results = complete_forecasting_workflow(\n",
    "    data=economic_data,\n",
    "    target_col='unemployemnt',  # or 'Consumer Price Index', etc.\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632fdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
